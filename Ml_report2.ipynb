{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MATH2319 Machine Learning Project Phase 2\n",
    "                                                                                           \n",
    "  ## Predicting if the client will subscribe (yes/no) a term deposit\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                                                                                 \n",
    "                                                                                                \n",
    "                                                                                                   \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  >  **Names**: Junaid Ahmed Syed & Saikat Mitra\n",
    " \n",
    " \n",
    " \n",
    " \n",
    " >  **Student ID's**: s3731300 & s3726313\n",
    "  \n",
    "  \n",
    "  \n",
    "  \n",
    "  \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "The Goal of this project is to fit and compare 3 classifiers of binary cardinality to predict if the client will subscribe (yes/no) to a term deposit using the 1994 US Census Data sourced from the UCI Machine Learning Repository<strong data-cite=\"bank_uci\">(UCI, 2014)</strong>.. There are 20 descriptive features out of which 10 are numeric and 9 nominal categorical features and 1 ordinal categorical feature. The target feature has two classes defined as \"no\" and \"yes\" respectively. The full dataset contains about 45K observations. This report is a continuation of phase 1 which has included a brief description, pre-processing and visualization of the data.\n",
    "This report is organized as follows. Section 2  (Overview)  our methodology. Section 3 involves  (Data Preparation)  data pre-processing. In Section 4, we have done the hyperparameter tuning process for each classification algorithm. In Section 5  (Performance Comparison) we present model performance comparison. Section 6  discusses the limitations of our approach. In the last section is to present a brief summary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "The strategy of modelling starts with cleaning the full dataset which has been done in  Phase I. This transformation further includes encoding both nominal and ordinal categorical descriptive features as numerical and then normalising the data of descriptive features using MinMax Scaler. We first randomly sample 5K rows from the full dataset and then split this sample into training and test sets with a 70:30 ratio. Then our train dataset has 3.5K rows and test dataset has 1.5K rows.\n",
    "\n",
    "\n",
    "Out of all 20 features,  10 features are selected using Random Forest Importance method inside a pipeline. We consider 10, 20, and the full set of features (with 50 features)\n",
    "\n",
    "Using feature selection together with hyperparameter search inside a single pipeline, we conduct 5-fold stratified cross-validation to fine-tune hyperparameters to each of the following classifiers using the area under the curve (AUC) as the performance.\n",
    "\n",
    "* K-Nearest Neighbors (KNN),\n",
    "* Decision trees (DT), and\n",
    "* Naive Bayes (NB).\n",
    "\n",
    "The best parameters will be identified for each of the three classifier types using a hyperparameter search on the training data. Then we conduct 10-fold cross-validation on the test data and perform a paired t-test. In addition, we compare the classifiers with respect to their recall scores, confusion matrices and accuracy_scores on the test data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation\n",
    "## Loading Dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41188, 21)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['age', 'job', 'marital', 'education', 'default', 'housing', 'loan',\n",
       "       'contact', 'month', 'day_of_week', 'duration', 'campaign', 'pdays',\n",
       "       'previous', 'poutcome', 'emp.var.rate', 'cons.price.idx',\n",
       "       'cons.conf.idx', 'euribor3m', 'nr.employed', 'y'], dtype=object)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "Bank_ds = pd.read_csv('bank-additional-full.csv', sep=';')\n",
    "\n",
    "print(Bank_ds.shape)\n",
    "\n",
    "Bank_ds.columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shape of the dataset\n",
    "First we check the shape of the dataset to confirm that the features are matched with the description as outlined in the document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension of the data set is{Bank.shape}\n",
      "\n",
      "Data Types are:\n",
      "age                 int64\n",
      "job                object\n",
      "marital            object\n",
      "education          object\n",
      "default            object\n",
      "housing            object\n",
      "loan               object\n",
      "contact            object\n",
      "month              object\n",
      "day_of_week        object\n",
      "duration            int64\n",
      "campaign            int64\n",
      "pdays               int64\n",
      "previous            int64\n",
      "poutcome           object\n",
      "emp.var.rate      float64\n",
      "cons.price.idx    float64\n",
      "cons.conf.idx     float64\n",
      "euribor3m         float64\n",
      "nr.employed       float64\n",
      "y                  object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(\"Dimension of the data set is{Bank.shape}\\n\")\n",
    "print(\"Data Types are:\")\n",
    "print(Bank_ds.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are dropping 3 columns from the dataset as from the the visualisations which were done phase 1 report,we can see that these columns has no predictive power. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bank_ds=Bank_ds.drop(['duration'],1)\n",
    "Bank_ds=Bank_ds.drop(['poutcome'],1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking for missing values\n",
    " We can see that there are no missing values in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age               0\n",
       "job               0\n",
       "marital           0\n",
       "education         0\n",
       "default           0\n",
       "housing           0\n",
       "loan              0\n",
       "contact           0\n",
       "month             0\n",
       "day_of_week       0\n",
       "campaign          0\n",
       "pdays             0\n",
       "previous          0\n",
       "emp.var.rate      0\n",
       "cons.price.idx    0\n",
       "cons.conf.idx     0\n",
       "euribor3m         0\n",
       "nr.employed       0\n",
       "y                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Bank_ds.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding Categorical Descriptive Features\n",
    "Seperating target and descriptive features and labeling them as Bank and target respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "no     36548\n",
       "yes     4640\n",
       "Name: y, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Bank = Bank_ds.drop(columns='y')\n",
    "target = Bank_ds['y']\n",
    "target.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding Target variable \n",
    "To encode Target variable as 0 and 1 we use LableEncoder from the sklearn preprocessing module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "le_fit = le.fit(target)\n",
    "target = le_fit.transform(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding Categorical Descriptive Features\n",
    "\n",
    "#### Integer-encoding for ordinal Categorical Features\n",
    "\n",
    "\n",
    "Among all the descriptive features, `education` column is ordinal so we have used integer encoding for ordinal categorical features and labelled them with integer starting from 0 to 7 using replace function.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6    12168\n",
       "5     9515\n",
       "4     6045\n",
       "7     5243\n",
       "2     4176\n",
       "3     2292\n",
       "0     1731\n",
       "1       18\n",
       "Name: education, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "level_mapping = {'unknown': 0, 'illiterate': 1, 'basic.4y': 2,'basic.6y': 3,'basic.9y': 4,\n",
    "                 'high.school': 5, 'university.degree': 6,'professional.course': 7}\n",
    "Bank['education'] = Bank['education'].replace(level_mapping)\n",
    "Bank['education'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hot-encoding for Nomial Categorical Features\n",
    "\n",
    "For converting Nomial Categorical Features to numerical we did one-hot encoding we defined a custom function for each two-level categorical variable. For columns of level 0,1 we set the drop_first option to true to encode them into a single column and for the columns more than 2 levels we apply the get_dummies()  for the regular one-hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical = Bank.columns[Bank.dtypes==object].tolist()\n",
    "\n",
    "for col in categorical:\n",
    "    n = len(Bank[col].unique())\n",
    "    if (n == 2):\n",
    "        Bank[col] = pd.get_dummies(Bank[col], drop_first=True)\n",
    "\n",
    "Bank = pd.get_dummies(Bank)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After this step , we can see that the  Descriptive feature set has 50 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'education', 'contact', 'campaign', 'pdays', 'previous',\n",
       "       'emp.var.rate', 'cons.price.idx', 'cons.conf.idx', 'euribor3m',\n",
       "       'nr.employed', 'job_admin.', 'job_blue-collar', 'job_entrepreneur',\n",
       "       'job_housemaid', 'job_management', 'job_retired', 'job_self-employed',\n",
       "       'job_services', 'job_student', 'job_technician', 'job_unemployed',\n",
       "       'job_unknown', 'marital_divorced', 'marital_married', 'marital_single',\n",
       "       'marital_unknown', 'default_no', 'default_unknown', 'default_yes',\n",
       "       'housing_no', 'housing_unknown', 'housing_yes', 'loan_no',\n",
       "       'loan_unknown', 'loan_yes', 'month_apr', 'month_aug', 'month_dec',\n",
       "       'month_jul', 'month_jun', 'month_mar', 'month_may', 'month_nov',\n",
       "       'month_oct', 'month_sep', 'day_of_week_fri', 'day_of_week_mon',\n",
       "       'day_of_week_thu', 'day_of_week_tue', 'day_of_week_wed'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Bank.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling Descriptive Features\n",
    "After converting all the features to numeric, we normalized them by using MinMax Scalar. Before doing that, we save a normal copy of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bank_df = Bank.copy()\n",
    "Scaler = preprocessing.MinMaxScaler()\n",
    "Scaler.fit(Bank)\n",
    "Bank = Scaler.fit_transform(Bank)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection\n",
    "For Simplicity, we are selecting 10 most important features  selected by Random Forest Importance (RFI) from the full dataset. This is for a quick ranking of the most relevant 10 features to gain some insight into the problem at hand. During the hyperparameter tuning phase, we will include RFI as part of the pipeline and we will search over 10, 20, and the full set of 50 features to determine which number of features works best with each classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['age', 'euribor3m', 'campaign', 'education', 'pdays',\n",
       "       'nr.employed', 'emp.var.rate', 'previous', 'cons.price.idx',\n",
       "       'cons.conf.idx'], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "num_features = 10\n",
    "model_rfi = RandomForestClassifier(n_estimators=100)\n",
    "model_rfi.fit(Bank, target)\n",
    "fs_indices_rfi = np.argsort(model_rfi.feature_importances_)[::-1][0:num_features]\n",
    "\n",
    "best_features_rfi = Bank_df.columns[fs_indices_rfi].values\n",
    "best_features_rfi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.17227963, 0.12457136, 0.08652432, 0.07071197, 0.05193277,\n",
       "       0.04711875, 0.02995865, 0.02876424, 0.02340576, 0.02075894])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importances_rfi = model_rfi.feature_importances_[fs_indices_rfi]\n",
    "feature_importances_rfi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Visualising the important features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.vegalite.v2+json": {
       "$schema": "https://vega.github.io/schema/vega-lite/v2.6.0.json",
       "config": {
        "view": {
         "height": 300,
         "width": 400
        }
       },
       "data": {
        "name": "data-6d3b3789037da6403a6ea66530bae52d"
       },
       "datasets": {
        "data-6d3b3789037da6403a6ea66530bae52d": [
         {
          "features": "age",
          "importances": 0.1722796263260232
         },
         {
          "features": "euribor3m",
          "importances": 0.12457135575845614
         },
         {
          "features": "campaign",
          "importances": 0.08652431674436963
         },
         {
          "features": "education",
          "importances": 0.0707119692469036
         },
         {
          "features": "pdays",
          "importances": 0.051932770254550516
         },
         {
          "features": "nr.employed",
          "importances": 0.04711875492551508
         },
         {
          "features": "emp.var.rate",
          "importances": 0.029958649358777983
         },
         {
          "features": "previous",
          "importances": 0.028764240289636377
         },
         {
          "features": "cons.price.idx",
          "importances": 0.023405761482191093
         },
         {
          "features": "cons.conf.idx",
          "importances": 0.020758940620409755
         }
        ]
       },
       "encoding": {
        "x": {
         "axis": {
          "labelAngle": 45
         },
         "field": "features",
         "sort": null,
         "title": "Feature",
         "type": "nominal"
        },
        "y": {
         "field": "importances",
         "title": "Importance",
         "type": "quantitative"
        }
       },
       "mark": {
        "color": "red",
        "opacity": 0.85,
        "type": "bar"
       },
       "title": "Random Forest Feature Importances",
       "width": 500
      },
      "image/png": "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",
      "text/plain": [
       "<VegaLite 2 object>\n",
       "\n",
       "If you see this message, it means the renderer has not been properly enabled\n",
       "for the frontend that you are using. For more information, see\n",
       "https://altair-viz.github.io/user_guide/troubleshooting.html\n"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import altair as alt\n",
    "\n",
    "def plot_imp(best_features, scores, method_name, color):\n",
    "    \n",
    "    df = pd.DataFrame({'features': best_features, \n",
    "                       'importances': scores})\n",
    "    \n",
    "    chart = alt.Chart(df, \n",
    "                      width=500, \n",
    "                      title=method_name + ' Feature Importances'\n",
    "                     ).mark_bar(opacity=0.85, \n",
    "                                color=color).encode(\n",
    "        alt.X('features', title='Feature', sort=None, axis=alt.AxisConfig(labelAngle=45)),\n",
    "        alt.Y('importances', title='Importance')\n",
    "    )\n",
    "    \n",
    "    return chart\n",
    "\n",
    "plot_imp(best_features_rfi, feature_importances_rfi, 'Random Forest', 'red')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Sampling & Train-Test Splitting\n",
    "The full dataset has more than 45K rows. So, we have randomly selected a small sample of  5K rows and Split this sample into train and test with a ratio of  70:30 ratio using the stratification method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 51)\n",
      "(5000, 1)\n"
     ]
    }
   ],
   "source": [
    "sample = 5000\n",
    "\n",
    "Data_s = pd.DataFrame(Bank).sample(n=sample, random_state=8).values\n",
    "target_s = pd.DataFrame(target).sample(n=sample, random_state=8).values\n",
    "\n",
    "print(Data_s.shape)\n",
    "print(target_s.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3500, 51)\n",
      "(1500, 51)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "DStrain, DStest, \\\n",
    "TStrain, TStest = train_test_split(Data_s, target_s, \n",
    "                                                    test_size = 0.3, random_state=999,\n",
    "                                                    stratify = target_s)\n",
    "\n",
    "print(DStrain.shape)\n",
    "print(DStest.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation Strategy\n",
    "\n",
    "So, we shall be training and tuning our models on 3.5K rows of training data and we will test them on 1.5K rows of test data.\n",
    "\n",
    "For each these models, we will utilize 5-crease stratified cross-approval assessment strategy (with no reiterations for shorter run times) for hyperparameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "\n",
    "cv_method = StratifiedKFold(n_splits=5, random_state=999)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning \n",
    "\n",
    "## K-Nearest Neighbors (KNN)\n",
    "\n",
    "Using Pipeline, we stack feature selection and grid search for KNN hyperparameter tuning via cross-validation. We will use the same Pipeline methodology for NB and DT.\n",
    "\n",
    "The KNN hyperparameters are as follows:\n",
    "\n",
    "number of neighbours (n_neighbors) and\n",
    "the distance metric p.\n",
    "For feature selection, we use the powerful Random Forest Importance (RFI) method with 100 estimators, we define the custom RFIFeatureSelector() class below to pass in RFI as a \"step\" to the pipeline to make RFI feature selection as part of the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "# custom function for RFI feature selection inside a pipeline\n",
    "# here we use n_estimators=100\n",
    "class RFIFeatureSelector(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    # class constructor \n",
    "    # make sure class attributes end with a \"_\"\n",
    "    # per scikit-learn convention to avoid errors\n",
    "    def __init__(self, n_features_=10):\n",
    "        self.n_features_ = n_features_\n",
    "        self.fs_indices_ = None\n",
    "\n",
    "    # override the fit function\n",
    "    def fit(self, X, y):\n",
    "        from sklearn.ensemble import RandomForestClassifier\n",
    "        from numpy import argsort\n",
    "        model_rfi = RandomForestClassifier(n_estimators=100)\n",
    "        model_rfi.fit(X, y)\n",
    "        self.fs_indices_ = argsort(model_rfi.feature_importances_)[::-1][0:self.n_features_] \n",
    "        return self \n",
    "    \n",
    "    # override the transform function\n",
    "    def transform(self, X, y=None):\n",
    "        return X[:, self.fs_indices_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "pipe_KNN = Pipeline(steps=[('rfi_fs', RFIFeatureSelector()), \n",
    "                           ('knn', KNeighborsClassifier())])\n",
    "\n",
    "params_pipe_KNN = {'rfi_fs__n_features_': [10, 20, Bank.shape[1]],\n",
    "                   'knn__n_neighbors': [1, 10, 20,40,60,100],\n",
    "                   'knn__p': [1, 2]}\n",
    "\n",
    "GridSearchCVKNN = GridSearchCV(estimator=pipe_KNN, \n",
    "                           param_grid=params_pipe_KNN, \n",
    "                           cv=cv_method,\n",
    "                           refit=True,\n",
    "                           n_jobs=-2,\n",
    "                           scoring='roc_auc',\n",
    "                           verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-2)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=-2)]: Done  44 tasks      | elapsed:    8.2s\n",
      "[Parallel(n_jobs=-2)]: Done 180 out of 180 | elapsed:   47.5s finished\n"
     ]
    }
   ],
   "source": [
    "GridSearchCVKNN.fit(DStrain, TStrain);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'knn__n_neighbors': 100, 'knn__p': 1, 'rfi_fs__n_features_': 10}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GridSearchCVKNN.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7594934714541964"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GridSearchCVKNN.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the best  KNN model given by the grid search method has an average AUC score of 0.759. The best accomplishing KNN selected 10 features with 100 nearest neighbours and =1.\n",
    "\n",
    "\n",
    "let's see the other combinations to see if the difference is rather meaningful or not. To do that, we will make use of the function below to format the grid search outputs as pd."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_search_results(gs):\n",
    "\n",
    "    def model_result(scores, params):\n",
    "        scores = {'mean_score': np.mean(scores),\n",
    "             'std_score': np.std(scores),\n",
    "             'min_score': np.min(scores),\n",
    "             'max_score': np.max(scores)}\n",
    "        return pd.Series({**params,**scores})\n",
    "\n",
    "    models = []\n",
    "    scores = []\n",
    "\n",
    "    for i in range(gs.n_splits_):\n",
    "        key = f\"split{i}_test_score\"\n",
    "        r = gs.cv_results_[key]        \n",
    "        scores.append(r.reshape(-1,1))\n",
    "\n",
    "    all_scores = np.hstack(scores)\n",
    "    for p, s in zip(gs.cv_results_['params'], all_scores):\n",
    "        models.append((model_result(s, p)))\n",
    "\n",
    "    pipe_results = pd.concat(models, axis=1).T.sort_values(['mean_score'], ascending=False)\n",
    "\n",
    "    columns_first = ['mean_score', 'std_score', 'max_score', 'min_score']\n",
    "    columns = columns_first + [c for c in pipe_results.columns if c not in columns_first]\n",
    "\n",
    "    return pipe_results[columns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gs_pipe_KNN' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-e2ed12c70c60>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresults_KNN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_search_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgs_pipe_KNN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mresults_KNN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'gs_pipe_KNN' is not defined"
     ]
    }
   ],
   "source": [
    "results_KNN = get_search_results(gs_pipe_KNN)\n",
    "results_KNN.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- visualising these results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import altair as alt\n",
    "\n",
    "results_KNN_10_features = results_KNN[results_KNN['rfi_fs__n_features_'] == 10.0]\n",
    "\n",
    "alt.Chart(results_KNN_10_features, \n",
    "          title='KNN Performance Comparison with 10 Features'\n",
    "         ).mark_line(point=True).encode(\n",
    "    alt.X('knn__n_neighbors', title='Number of Neighbors'),\n",
    "    alt.Y('mean_score', title='AUC Score', scale=alt.Scale(zero=False)),\n",
    "    alt.Color('knn__p:N', title='p')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Gaussian) Naive Bayes (NB)\n",
    "\n",
    "For Implementing a Gaussian Naive Bayes model, we optimize var_smoothing (a variation of Laplace smoothing) as we don't have any earlier data about our dataset. Of course, the var_smoothing parameter's esteem is 109. We lead the lattice search in the log space (over the forces of 10) sourced from NumPy. We begin with 10 and end with 103 with 200 different values, however, we perform a random search over only 20 different values (for shorter run times). Since NB requires each descriptive feature to follow a Gaussian Distribution, we initially play out a power change(Transformation) on the information before model fitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PowerTransformer\n",
    "DStransformed = PowerTransformer().fit_transform(DStrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "pipe_NB = Pipeline([('rfi_fs', RFIFeatureSelector()), \n",
    "                     ('nb', GaussianNB())])\n",
    "\n",
    "params_pipe_NB  = {'rfi_fs__n_features_': [10, 20, Bank.shape[1]],\n",
    "                  'nb__var_smoothing': np.logspace(1,-3,num=200)}\n",
    "\n",
    "n_iter_search = 20\n",
    "gs_pipe_NB = RandomizedSearchCV(estimator=pipe_NB, \n",
    "                          param_distributions=params_pipe_NB, \n",
    "                          cv=cv_method,\n",
    "                          refit=True,\n",
    "                          n_jobs=-2,\n",
    "                          scoring='roc_auc',\n",
    "                          n_iter=n_iter_search,\n",
    "                          verbose=1) \n",
    "\n",
    "gs_pipe_NB.fit(DStransformed, TStrain);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_pipe_NB.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_pipe_NB.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best NB has an AUC score of 0.754 with 50 features, which is slightly less than KNN.we can also see that the with gridsearch the optimal number of features is 50 rather than 10.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_NB = get_search_results(gs_pipe_NB)\n",
    "results_NB.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- visualize the search results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_NB_10_features = results_NB[results_NB['rfi_fs__n_features_'] == 10.0]\n",
    "\n",
    "alt.Chart(results_NB_10_features, \n",
    "          title='NB Performance Comparison with 10 Features'\n",
    "         ).mark_line(point=True).encode(\n",
    "    alt.X('nb__var_smoothing', title='Var. Smoothing'),\n",
    "    alt.Y('mean_score', title='AUC Score', scale=alt.Scale(zero=False))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree (DT)\n",
    "We build a Decision Tree model using the Gini Index to increase Information Gain. We aim to determine the best values of maximum depth (max_depth) and minimum sample split (min_samples_split). We conduct the grid search with values of 3, 5,7,9 for  max_depth and 5,10,15 for  min_samples_split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "pipe_DT = Pipeline([('rfi_fs', RFIFeatureSelector()),\n",
    "                    ('dt', DecisionTreeClassifier(criterion='gini'))])\n",
    "params_pipe_DT = {'rfi_fs__n_features_': [10, 20, Bank.shape[1]],\n",
    "                  'dt__max_depth': [3, 5, 7, 9],\n",
    "                  'dt__min_samples_split': [5, 10, 15]}\n",
    "\n",
    "gs_pipe_DT = GridSearchCV(estimator=pipe_DT, \n",
    "                          param_grid=params_pipe_DT, \n",
    "                          cv=cv_method,\n",
    "                          refit=True,\n",
    "                          n_jobs=-2,\n",
    "                          scoring='roc_auc',\n",
    "                          verbose=1) \n",
    "\n",
    "gs_pipe_DT.fit(DStrain, TStrain);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_pipe_DT.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_pipe_DT.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The optimal DT has a dt_max_depth of 3 and dt__min_samples_split value of 5 samples with an AUC score of 0.73. \n",
    "- A visualization of the search results is given below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_DT = get_search_results(gs_pipe_DT)\n",
    "\n",
    "results_DT_10_features = results_DT[results_DT['rfi_fs__n_features_'] == 10.0]\n",
    "\n",
    "alt.Chart(results_DT_10_features, \n",
    "          title='DT Performance Comparison with 10 Features'\n",
    "         ).mark_line(point=True).encode(\n",
    "    alt.X('dt__min_samples_split', title='Min Samples for Split'),\n",
    "    alt.Y('mean_score', title='AUC Score', scale=alt.Scale(zero=False)),\n",
    "    alt.Color('dt__max_depth:N', title='Max Depth')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance Comparision\n",
    "We have improved every last one of the three classifiers utilizing the train data. We currently fit the improved models on test data in a cross-validated style. Be that as it may, since cross validation itself is a random procedure, we perform pairwise t-tests to decide whether any contrast between the exhibition of any two optimized classifiers that are statistically significant. To start with, we perform 10-fold stratified cross-validation on each best model (with no redundancies). Second, we lead a paired t-test for the AUC score between the accompanying model combinations:\n",
    "\n",
    "KNN vs. NB,\n",
    "\n",
    "\n",
    "KNN vs. DT, and\n",
    "\n",
    "\n",
    "DT vs. NB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cv_method_ttest = StratifiedKFold(n_splits=10, random_state=999)\n",
    "\n",
    "cv_results_KNN = cross_val_score(estimator=gs_pipe_KNN.best_estimator_,\n",
    "                                 X=DStest,\n",
    "                                 y=TStest,\n",
    "                                 cv=cv_method_ttest,\n",
    "                                 n_jobs=-2,\n",
    "                                 scoring='roc_auc')\n",
    "cv_results_KNN.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DStransformed = PowerTransformer().fit_transform(DStest)\n",
    "\n",
    "cv_results_NB = cross_val_score(estimator=gs_pipe_NB.best_estimator_,\n",
    "                                X=DStransformed,\n",
    "                                y=TStest, \n",
    "                                cv=cv_method_ttest, \n",
    "                                n_jobs=-2,\n",
    "                                scoring='roc_auc')\n",
    "cv_results_NB.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results_DT = cross_val_score(estimator=gs_pipe_DT.best_estimator_,\n",
    "                                X=DStest,\n",
    "                                y=TStest, \n",
    "                                cv=cv_method_ttest, \n",
    "                                n_jobs=-2,\n",
    "                                scoring='roc_auc')\n",
    "cv_results_DT.mean()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Since we have a constant random state , all classifiers were fitted and then tested on exactly the same test data partitions. We use the stats.ttest_rel()which is from the SciPy module to run the following t-tests on test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "print(stats.ttest_rel(cv_results_KNN, cv_results_NB))\n",
    "print(stats.ttest_rel(cv_results_DT, cv_results_KNN))\n",
    "print(stats.ttest_rel(cv_results_DT, cv_results_NB))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can see that at a 95% significance level, KNN is measurably the best model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Though we used AUC to optimize the algorithm hyperparameters, we shall consider the following metrics to evaluate models based on the test set:\n",
    "\n",
    "- Accuracy\n",
    "- Precision\n",
    "- Recall\n",
    "- F1 Score (the harmonic average of precision and recall)\n",
    "- Confusion Matrix\n",
    "\n",
    "\n",
    "These metrics can be computed using classification_report from sklearn.metrics. The classification reports are shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_KNN = gs_pipe_KNN.predict(DStest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_test_transformed = PowerTransformer().fit_transform(DStest)\n",
    "pred_NB = gs_pipe_NB.predict(DStransformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_DT = gs_pipe_DT.predict(DStest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "print(\"\\nClassification report for K-Nearest Neighbor\") \n",
    "print(metrics.classification_report(TStest, pred_KNN))\n",
    "print(\"\\nClassification report for Naive Bayes\") \n",
    "print(metrics.classification_report(TStest, pred_NB))\n",
    "print(\"\\nClassification report for Decision Tree\") \n",
    "print(metrics.classification_report(TStest, pred_DT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "print(\"\\nConfusion matrix for K-Nearest Neighbor\") \n",
    "print(metrics.confusion_matrix(TStest, pred_KNN))\n",
    "print(\"\\nConfusion matrix for Naive Bayes\") \n",
    "print(metrics.confusion_matrix(TStest, pred_NB))\n",
    "print(\"\\nConfusion matrix for Decision Tree\") \n",
    "print(metrics.confusion_matrix(TStest, pred_DT))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we would pick recall as the performance metric, which is comparable to the true positive rate (TPR). In this unique circumstance, DT would be the best performer since it delivers the most astounding recall score for customers who subscribed to a term deposit. The confusion matrices are in accordance with the classification reports. This is in a contrast to our finding that KNN is measurably the best model with regards to the AUC metric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Limitations and Proposed Solutions \n",
    "Our modelling strategy has a couple of imperfections and confinements. To start with, ours was a black-box approach since we preferred raw predictive performance over interpretability. Later on, In the future, we could consider a more inside and out an investigation of feature selection & ranking process as well as our choices for the hyperparameter spaces.\n",
    "\n",
    "Second, we used a blanket power transformation on the training data when building the NB, disregarding the dummy features in the dataset. This may somewhat clarify the poor execution of the NB when assessed on the test set. A potential solution is to build a Gaussian NB and a Bernoulli NB independently on the numerical and dummy descriptive features individually. At that point, we can compute a final prediction by multiplying predictions from each model since NB assumes inter-independence conditioned on the value of the target feature.\n",
    "\n",
    "Third, The feature selection with ten best features hasn't worked well. We have seen 20 and 51 as the best number of features. For this, in future, we can increase the number of important features and check whether we get Better Results.\n",
    "\n",
    "Lastly, we just worked with a little subset of the full dataset for shorter run times, both for preparing and testing. Since information is constantly significant, we could re-run our trials with the whole information while ensuring that the train and test split is performed in a legitimate manner.\n",
    "\n",
    "\n",
    "The KNN classifier statistically outperforms the other two models. Therefore, we can perhaps improve it by further expanding the hyperparameter search space by including other parameters of this classification method. Furthermore, we can consider random forests and other ensemble methods built on trees as potentially better models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary \n",
    "The K-Nearest Neighbors (KNN) model with 10 of the best features chosen by Random Forest Importance (RFI) produces the highest cross-validated AUC score on the train data. Also, when assessed on the test set, the Decision Tree model got high precision score and most astounding review score which again beats both Naive Bayes and k-Nearest Neighbor models concerning AUC. Since we can see that the number of features of DT model is 20 and 51 for NB model We can observe that our models is sensitive to the number of features. For this reason, we should work with full feature set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "* S. Moro, P. Cortez and P. Rita,(2014),Bank-Marketing Data Set,https://archive.ics.uci.edu/ml/datasets/Bank+Marketing"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
